{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multiple Linear Regression**\n",
    "- Multiple Linear Regression (MLR) is a supervised learning algorithm that predicts a continuous dependent variable based on two or more independent variables. It extends the simple linear regression model to accommodate multiple features.\n",
    "- MLR models the relationship between a dependent variable Y and multiple independent variables X1, X2, ..., Xn. The model assumes a linear relationship and finds the best-fitting hyperplane in the multi-dimensional feature space.\n",
    "\n",
    "**Key concepts:**\n",
    "- **Dependent Variable (Y):** The target variable to predict.\n",
    "- **Independent Variables (X):** Features used to make predictions.\n",
    "- **Coefficients (b):** Weights for each feature indicating their impact on Y.\n",
    "- **Intercept (b0):** The point where the hyperplane crosses the Y-axis when all X are zero.\n",
    "- **Error Term (e):** Represents the unexplained variance or noise in the model.\n",
    "\n",
    "**How it works and how is it used?**\n",
    "MLR works by finding the hyperplane in the feature space that minimizes the Residual Sum of Squares (RSS). The model fits the equation:\n",
    "```\n",
    "Y = b0 + b1*X1 + b2*X2 + ... + bn*Xn + e\n",
    "```\n",
    "\n",
    "**Usage**:\n",
    "- Forecasting and predicting outcomes based on multiple factors.\n",
    "- Analyzing the relative impact of each independent variable on Y.\n",
    "- Applications in finance, healthcare, marketing, and engineering.\n",
    "\n",
    "**List of Important Types**\n",
    "- **Ordinary Least Squares (OLS):** The most common type, minimizing the sum of squared residuals.\n",
    "- **Stepwise Regression:** Selects significant variables step-by-step.\n",
    "- **Ridge Regression:** Adds L2 regularization to reduce overfitting.\n",
    "- **Lasso Regression:** Adds L1 regularization, encouraging sparsity in coefficients.\n",
    "- **ElasticNet Regression:** Combines Ridge and Lasso penalties for improved performance.\n",
    "\n",
    "**Goal**\n",
    "To model the relationship between a dependent variable and multiple independent variables, predict future outcomes, and quantify the importance of each independent variable.\n",
    "\n",
    "**Important Formula**\n",
    "The formula for multiple linear regression is:\n",
    "```\n",
    "Y = b0 + b1*X1 + b2*X2 + ... + bn*Xn + e\n",
    "```\n",
    "Where:\n",
    "- Y: Predicted dependent variable\n",
    "- b0: Intercept\n",
    "- b1, b2, ..., bn: Coefficients of independent variables\n",
    "- X1, X2, ..., Xn: Independent variables\n",
    "- e: Error term\n",
    "\n",
    "**Example**\n",
    "**Dataset**: Predict house prices based on square footage, number of bedrooms, and proximity to schools.\n",
    "\n",
    "| Square Footage (X1) | Bedrooms (X2) | Proximity to School (X3) | Price (Y) |\n",
    "|---------------------|---------------|--------------------------|-----------|\n",
    "| 2000               | 3             | 1                        | 400,000   |\n",
    "| 1500               | 2             | 3                        | 300,000   |\n",
    "| 2500               | 4             | 2                        | 500,000   |\n",
    "\n",
    "MLR identifies how each feature contributes to the final price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 0.39999839989468455\n",
      "Coefficients: [1.99999200e+02 3.99998400e-01 1.82131091e-11]\n",
      "Predicted Prices: [400000. 300000. 500000.]\n"
     ]
    }
   ],
   "source": [
    "#### 8. **Python Code**\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Sample Data\n",
    "data = {\n",
    "    'Square_Footage': [2000, 1500, 2500],\n",
    "    'Bedrooms': [3, 2, 4],\n",
    "    'Proximity_to_School': [1, 3, 2],\n",
    "    'Price': [400000, 300000, 500000]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Features and Target\n",
    "X = df[['Square_Footage', 'Bedrooms', 'Proximity_to_School']]\n",
    "y = df['Price']\n",
    "\n",
    "# Model\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Coefficients and Intercept\n",
    "print(f\"Intercept: {model.intercept_}\")\n",
    "print(f\"Coefficients: {model.coef_}\")\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X)\n",
    "print(f\"Predicted Prices: {y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Real World Scenario**\n",
    "**Scenario**: Predicting employee salaries based on experience, education level, and location.\n",
    "- **Problem**: A company wants to establish a salary range for incoming candidates.\n",
    "- **Application**: MLR helps determine how much each factor (experience, education, location) influences salary.\n",
    "\n",
    "**Problem Statement**\n",
    "Given a dataset containing various features of houses (size, number of rooms, location), predict the house price for a new set of feature values.\n",
    "\n",
    "**How it can help**\n",
    "- Understand the relative importance of different factors in determining an outcome.\n",
    "- Predict future values with reasonable accuracy.\n",
    "- Optimize processes and strategies by focusing on significant predictors.\n",
    "\n",
    "**Alternate Solution**\n",
    "If the relationship between features and the target variable is non-linear, use Polynomial Regression, Decision Trees, or Random Forest Regression for better performance.\n",
    "\n",
    "**Final Important Note About the Topic**\n",
    "Multiple linear regression assumes:\n",
    "- A linear relationship between the dependent and independent variables.\n",
    "- Independence of features (low multicollinearity).\n",
    "- Homoscedasticity (constant variance of residuals).\n",
    "- Normally distributed residuals.\n",
    "\n",
    "Violations of these assumptions can lead to biased or unreliable predictions. Always validate the model and test assumptions before relying on the results.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
